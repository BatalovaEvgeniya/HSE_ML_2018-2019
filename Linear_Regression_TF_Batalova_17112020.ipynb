{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_Regression_TF_Batalova_17112020",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BatalovaEvgeniya/HSE_ML_2018-2019/blob/master/Linear_Regression_TF_Batalova_17112020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZMe3Jq_0MLY"
      },
      "source": [
        "# Домашнее задание\n",
        "\n",
        "Будет две части домашнего задания.\n",
        "\n",
        "1. Реализовать линейную регрессию на \"низком уровне\" в tensorflow. Обучить модель.\n",
        "2. Улучшить слой keras API `Linear` так, чтобы линейная регрессия начала включать сдвиг (bias). Обучить и сравнить реузльтаты с моделью из прошлого задания. \n",
        "\n",
        "**Основная часть** инструкций и объяснений дана в ячейках рядом с частями задания. Если после прочтения инструкции или непонятно, как подступиться к задаче, напишите в слак Mikhail Stepanov.\n",
        "\n",
        "Задания 1 и 2 можно выполнять в любом порядке, но внутри задания лучше идти в порядке \"сверху вниз\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjFV9jcU2Ji9"
      },
      "source": [
        "# 1. Линейная регрессия\n",
        "\n",
        "Дополните существующий код так, чтобы он соотвествовал модели для линейной регрессии с использованием сдвига (bias)\n",
        "\n",
        "Скачайте датасет [отсюда](https://www.kaggle.com/aungpyaeap/fish-market) или из личного кабинета. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N9kHz7F6cI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb93f6d-93a7-4e9a-b930-a3115639558d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My\\ Drive/'OTUS. DL Basic'/HW_3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/OTUS. DL Basic/HW_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kszii992etr"
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('Fish.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OtO5BNv3nDd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "558c843b-a198-4102-82a2-f56f2635d3fe"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bream</td>\n",
              "      <td>242.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>25.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>11.5200</td>\n",
              "      <td>4.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bream</td>\n",
              "      <td>290.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>31.2</td>\n",
              "      <td>12.4800</td>\n",
              "      <td>4.3056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bream</td>\n",
              "      <td>340.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>26.5</td>\n",
              "      <td>31.1</td>\n",
              "      <td>12.3778</td>\n",
              "      <td>4.6961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bream</td>\n",
              "      <td>363.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.5</td>\n",
              "      <td>12.7300</td>\n",
              "      <td>4.4555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bream</td>\n",
              "      <td>430.0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>12.4440</td>\n",
              "      <td>5.1340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
              "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
              "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
              "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
              "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
              "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON7FFtYx3zrp"
      },
      "source": [
        "Поскольку мы будем выполнять регрессию, а не классификацию, то уберем из датасета данные о виде рыбы. Будем решать задачу по определению веса (Колонка `Weight`) по остальным параметрам (кроме `Species`).\n",
        "\n",
        "> Вы можете попробовать закодировать данные из столбца `Species` и использовать их для регрессии. Но поскольку мы с вами не разбирали эту тему, действуйте осторожно и начните с модели, не использующей эти данные, если решите пробовать."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEk3-v5a6Yeo"
      },
      "source": [
        "y = dataset['Weight'].values\n",
        "x = dataset[['Length1',\t'Length2', 'Length3',\t'Height',\t'Width']].values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQLZ25eQAXwu"
      },
      "source": [
        "### Подготовьте данные\n",
        "\n",
        "> Лучше нормализовать данные, чтобы модель была более численно стабильной\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YSrq8DfAY9V"
      },
      "source": [
        "x = (x - x.mean()) / x.std()\n",
        "y = (y - y.mean()) / y.std()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKF8nz55Ad4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "28102e28-d0d4-4263-e82c-87fcb66de3e8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.hist(y, bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cVUUtrf7_Q0"
      },
      "source": [
        "### Разделите данные\n",
        "\n",
        "Данные нужно разделить в отношении 80/20 на обучающую и валидационную выборки. Кросс-валидация, регуляризация вне темы данного занятия, поэтому не будем сосредотачиваться на этом вопросе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJW_w_6k6lYZ"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ-Kh_MQ6lKC"
      },
      "source": [
        "pivot = int(len(y) * 0.8)\n",
        "index = np.arange(len(dataset))\n",
        "np.random.shuffle(index)\n",
        "\n",
        "train_index, val_index = index[:pivot], index[pivot:]\n",
        "\n",
        "y_train, y_val = y[train_index], y[val_index]\n",
        "x_train, x_val = x[train_index], x[val_index]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtUAWXCK701-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG_f2mEz75mT"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOZTvQeCKdnM"
      },
      "source": [
        "### Инициализация\n",
        "\n",
        "Воспользуйтесь x.shape, чтобы задать правильную размерность вектора с параметрами. Проинициализируйте его случайными значеними.\n",
        "\n",
        "**Значение сдвига** `b = 0`; часто сдвиг или вектор сдвигов инициализируют нулями или средним по выборке значением, если оно отлично от нуля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q2r4exsKwLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8d599c-97b4-425a-81b5-a79b2cee98cb"
      },
      "source": [
        "x.shape[1:]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKpNBEdDCuF7"
      },
      "source": [
        "initial_value = tf.random.normal(shape=(x.shape[1], 1))\n",
        "w = initial_value \n",
        "b = tf.Variable(0, dtype=tf.float32)\n",
        "learning_rate = tf.constant(1e-4)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB7vWdNFLxXI"
      },
      "source": [
        "> Следующая функция описывает цикл обучения. Она работает корректно, в ней не обязательно что-то менять (но можно, если вам хочется)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bROqAToAB2rB"
      },
      "source": [
        "def fit(x, y, threshold=0.001, n_steps=10000):\n",
        "  x = tf.constant(x, dtype=tf.float32)\n",
        "  y = tf.constant(y, dtype=tf.float32)\n",
        "  w = tf.random.normal(shape=(x.shape[1], 1))\n",
        "  b = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        " # print('before loop')\n",
        "  for step in range(n_steps):\n",
        "  #  print('#:', step)\n",
        "    loss, w, b = train_step(w, x, y, b)\n",
        "    if loss < threshold:\n",
        "      break\n",
        "    if (step + 1) % 50 == 0:\n",
        "      print(f\"Loss at {step} iter. is {loss.numpy()}\")\n",
        "  #print(loss)\n",
        "  #print(w, b)      \n",
        "  return loss, w, b"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5sLUIo6K1qi"
      },
      "source": [
        "### Train step\n",
        "\n",
        "Дополните `train_step` так, чтобы функция вычисляла значение $\\hat{y}$ для переданного $x$, и затем значение функции ошибки с помощью функции `calc_loss`.\n",
        "\n",
        "Добавитье обновление параметров в строчке `w = ...`. *Если возвращаемое значение* функции ошибки равно `nan` или `inf`, подумайте, что могло привести к такой ситуации и что нужно исправить."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "220FT2sjCvUf"
      },
      "source": [
        "def train_step(w, x, y, b):\n",
        "  w = tf.Variable(w, dtype=tf.float32)\n",
        "  b = tf.Variable(b, dtype=tf.float32)\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_hat = tf.tensordot(x, w, 1) + b #model(w, x, b)\n",
        "    loss = calc_loss(y, y_hat)\n",
        "    dw, db= tape.gradient(loss, [w, b])\n",
        " # print(dw)\n",
        "  #print(db)\n",
        "  w = tf.subtract(w, learning_rate*dw)\n",
        "  b = tf.subtract(b, learning_rate*db)\n",
        " # print(w, b)\n",
        "  return loss, w, b"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfOeQT77L9CZ"
      },
      "source": [
        "Умножение вектора на вектор или вектора на строку в `tf` - это сложная операция. В отличие от матричного умножения, которое можно записать просто как `C = A @ B` или `C = tf.matmul(A, B)`, здесь нужно вызывать функцию `tf.tensordot`, которая способна умножать тензоры любой размерности. Затем функции надо указать ось, по которой выполняется сложение: в данном случае, 1 - т.е. для произведения матрицы на вектор нужно выполнить операцию\n",
        "\n",
        "`tf.tensordot(x, w, 1)`\n",
        "\n",
        "Воспользовавшись этим способом, напишите модель для линейной регрессии. Кстати, это не единственный возможный вариант [расчета скалярного произведения в tensorflow](https://stackoverflow.com/questions/40670370/dot-product-of-two-vectors-in-tensorflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY-xy39GCvf7"
      },
      "source": [
        "def model(w, x, b):\n",
        "  return   tf.tensordot(tf.constant(x, dtype=tf.float32), w, 1) + b\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY0J06VyM5N9"
      },
      "source": [
        "Напишите функцию, которая вычисляет значение MSE для двух переданных векторов со значениями $y, \\hat{y}$ (истинные и спрогнозированные значения). Функция должна возвращать _одно_ значение (скаляр), как и в формуле $\\frac{1}{n}\\sum_{i=1}^{n}(y^{(i)} - \\hat{y}^{(i)})^2$ \n",
        "\n",
        "* разность векторов и возведение в квадрат можно сделать при помощи обычных операторов `-`, `**2`\n",
        "* Для того, чтобы в тензорфлоу выполнить аналог операции $\\frac{1}{n}\\sum_{i=1}^n (...)$, воспользуйтесь функцией `tf.reduce_mean`. Заодно можете изучить, какие еще есть `tf.reduce_...` функции :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjGeu116FVgM"
      },
      "source": [
        "def calc_loss(y, y_hat):\n",
        "  return tf.reduce_mean(tf.square(y - y_hat))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxdd13XhLpYr"
      },
      "source": [
        "### Обучение\n",
        "\n",
        "> Обучите модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR7-3mraDnDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41166789-7e7c-43d8-c03a-bc59d2a1fcf1"
      },
      "source": [
        "loss_, w_, b_ = fit(x_train, y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at 49 iter. is 3.4245669841766357\n",
            "Loss at 99 iter. is 3.251248836517334\n",
            "Loss at 149 iter. is 3.093258857727051\n",
            "Loss at 199 iter. is 2.9491913318634033\n",
            "Loss at 249 iter. is 2.8177683353424072\n",
            "Loss at 299 iter. is 2.697833299636841\n",
            "Loss at 349 iter. is 2.5883350372314453\n",
            "Loss at 399 iter. is 2.4883203506469727\n",
            "Loss at 449 iter. is 2.3969223499298096\n",
            "Loss at 499 iter. is 2.313359022140503\n",
            "Loss at 549 iter. is 2.2369160652160645\n",
            "Loss at 599 iter. is 2.16694712638855\n",
            "Loss at 649 iter. is 2.1028668880462646\n",
            "Loss at 699 iter. is 2.0441431999206543\n",
            "Loss at 749 iter. is 1.9902924299240112\n",
            "Loss at 799 iter. is 1.9408761262893677\n",
            "Loss at 849 iter. is 1.8954966068267822\n",
            "Loss at 899 iter. is 1.8537930250167847\n",
            "Loss at 949 iter. is 1.8154369592666626\n",
            "Loss at 999 iter. is 1.7801318168640137\n",
            "Loss at 1049 iter. is 1.7476047277450562\n",
            "Loss at 1099 iter. is 1.7176116704940796\n",
            "Loss at 1149 iter. is 1.6899303197860718\n",
            "Loss at 1199 iter. is 1.6643569469451904\n",
            "Loss at 1249 iter. is 1.6407074928283691\n",
            "Loss at 1299 iter. is 1.6188151836395264\n",
            "Loss at 1349 iter. is 1.5985279083251953\n",
            "Loss at 1399 iter. is 1.5797079801559448\n",
            "Loss at 1449 iter. is 1.5622292757034302\n",
            "Loss at 1499 iter. is 1.5459781885147095\n",
            "Loss at 1549 iter. is 1.5308501720428467\n",
            "Loss at 1599 iter. is 1.5167516469955444\n",
            "Loss at 1649 iter. is 1.503596544265747\n",
            "Loss at 1699 iter. is 1.4913065433502197\n",
            "Loss at 1749 iter. is 1.4798107147216797\n",
            "Loss at 1799 iter. is 1.4690438508987427\n",
            "Loss at 1849 iter. is 1.4589475393295288\n",
            "Loss at 1899 iter. is 1.4494677782058716\n",
            "Loss at 1949 iter. is 1.4405558109283447\n",
            "Loss at 1999 iter. is 1.4321670532226562\n",
            "Loss at 2049 iter. is 1.4242604970932007\n",
            "Loss at 2099 iter. is 1.416799783706665\n",
            "Loss at 2149 iter. is 1.4097504615783691\n",
            "Loss at 2199 iter. is 1.4030811786651611\n",
            "Loss at 2249 iter. is 1.3967652320861816\n",
            "Loss at 2299 iter. is 1.390775203704834\n",
            "Loss at 2349 iter. is 1.385088324546814\n",
            "Loss at 2399 iter. is 1.3796828985214233\n",
            "Loss at 2449 iter. is 1.3745388984680176\n",
            "Loss at 2499 iter. is 1.3696389198303223\n",
            "Loss at 2549 iter. is 1.3649661540985107\n",
            "Loss at 2599 iter. is 1.3605053424835205\n",
            "Loss at 2649 iter. is 1.356242060661316\n",
            "Loss at 2699 iter. is 1.352164387702942\n",
            "Loss at 2749 iter. is 1.3482598066329956\n",
            "Loss at 2799 iter. is 1.3445180654525757\n",
            "Loss at 2849 iter. is 1.3409295082092285\n",
            "Loss at 2899 iter. is 1.3374838829040527\n",
            "Loss at 2949 iter. is 1.3341736793518066\n",
            "Loss at 2999 iter. is 1.3309903144836426\n",
            "Loss at 3049 iter. is 1.3279271125793457\n",
            "Loss at 3099 iter. is 1.3249777555465698\n",
            "Loss at 3149 iter. is 1.3221356868743896\n",
            "Loss at 3199 iter. is 1.3193950653076172\n",
            "Loss at 3249 iter. is 1.3167508840560913\n",
            "Loss at 3299 iter. is 1.3141980171203613\n",
            "Loss at 3349 iter. is 1.3117320537567139\n",
            "Loss at 3399 iter. is 1.3093490600585938\n",
            "Loss at 3449 iter. is 1.307044506072998\n",
            "Loss at 3499 iter. is 1.3048151731491089\n",
            "Loss at 3549 iter. is 1.3026576042175293\n",
            "Loss at 3599 iter. is 1.3005681037902832\n",
            "Loss at 3649 iter. is 1.29854416847229\n",
            "Loss at 3699 iter. is 1.296582579612732\n",
            "Loss at 3749 iter. is 1.2946802377700806\n",
            "Loss at 3799 iter. is 1.2928358316421509\n",
            "Loss at 3849 iter. is 1.291046142578125\n",
            "Loss at 3899 iter. is 1.2893095016479492\n",
            "Loss at 3949 iter. is 1.2876237630844116\n",
            "Loss at 3999 iter. is 1.2859864234924316\n",
            "Loss at 4049 iter. is 1.2843964099884033\n",
            "Loss at 4099 iter. is 1.282851219177246\n",
            "Loss at 4149 iter. is 1.2813501358032227\n",
            "Loss at 4199 iter. is 1.2798911333084106\n",
            "Loss at 4249 iter. is 1.2784727811813354\n",
            "Loss at 4299 iter. is 1.2770930528640747\n",
            "Loss at 4349 iter. is 1.2757513523101807\n",
            "Loss at 4399 iter. is 1.2744455337524414\n",
            "Loss at 4449 iter. is 1.27317476272583\n",
            "Loss at 4499 iter. is 1.2719378471374512\n",
            "Loss at 4549 iter. is 1.2707340717315674\n",
            "Loss at 4599 iter. is 1.2695622444152832\n",
            "Loss at 4649 iter. is 1.268420934677124\n",
            "Loss at 4699 iter. is 1.267309308052063\n",
            "Loss at 4749 iter. is 1.266226887702942\n",
            "Loss at 4799 iter. is 1.265171766281128\n",
            "Loss at 4849 iter. is 1.2641446590423584\n",
            "Loss at 4899 iter. is 1.2631433010101318\n",
            "Loss at 4949 iter. is 1.2621673345565796\n",
            "Loss at 4999 iter. is 1.261216402053833\n",
            "Loss at 5049 iter. is 1.2602888345718384\n",
            "Loss at 5099 iter. is 1.2593848705291748\n",
            "Loss at 5149 iter. is 1.2585031986236572\n",
            "Loss at 5199 iter. is 1.257643699645996\n",
            "Loss at 5249 iter. is 1.256805181503296\n",
            "Loss at 5299 iter. is 1.2559874057769775\n",
            "Loss at 5349 iter. is 1.2551894187927246\n",
            "Loss at 5399 iter. is 1.254410982131958\n",
            "Loss at 5449 iter. is 1.2536513805389404\n",
            "Loss at 5499 iter. is 1.2529101371765137\n",
            "Loss at 5549 iter. is 1.2521864175796509\n",
            "Loss at 5599 iter. is 1.2514803409576416\n",
            "Loss at 5649 iter. is 1.2507909536361694\n",
            "Loss at 5699 iter. is 1.2501176595687866\n",
            "Loss at 5749 iter. is 1.2494604587554932\n",
            "Loss at 5799 iter. is 1.2488186359405518\n",
            "Loss at 5849 iter. is 1.2481917142868042\n",
            "Loss at 5899 iter. is 1.2475793361663818\n",
            "Loss at 5949 iter. is 1.246980905532837\n",
            "Loss at 5999 iter. is 1.246396541595459\n",
            "Loss at 6049 iter. is 1.2458254098892212\n",
            "Loss at 6099 iter. is 1.2452671527862549\n",
            "Loss at 6149 iter. is 1.2447218894958496\n",
            "Loss at 6199 iter. is 1.244188666343689\n",
            "Loss at 6249 iter. is 1.243667721748352\n",
            "Loss at 6299 iter. is 1.243157982826233\n",
            "Loss at 6349 iter. is 1.242659568786621\n",
            "Loss at 6399 iter. is 1.2421722412109375\n",
            "Loss at 6449 iter. is 1.2416961193084717\n",
            "Loss at 6499 iter. is 1.24122953414917\n",
            "Loss at 6549 iter. is 1.240773320198059\n",
            "Loss at 6599 iter. is 1.24032723903656\n",
            "Loss at 6649 iter. is 1.2398903369903564\n",
            "Loss at 6699 iter. is 1.2394628524780273\n",
            "Loss at 6749 iter. is 1.2390445470809937\n",
            "Loss at 6799 iter. is 1.2386350631713867\n",
            "Loss at 6849 iter. is 1.238234043121338\n",
            "Loss at 6899 iter. is 1.2378414869308472\n",
            "Loss at 6949 iter. is 1.2374565601348877\n",
            "Loss at 6999 iter. is 1.2370797395706177\n",
            "Loss at 7049 iter. is 1.2367111444473267\n",
            "Loss at 7099 iter. is 1.23634934425354\n",
            "Loss at 7149 iter. is 1.2359950542449951\n",
            "Loss at 7199 iter. is 1.2356477975845337\n",
            "Loss at 7249 iter. is 1.2353073358535767\n",
            "Loss at 7299 iter. is 1.2349739074707031\n",
            "Loss at 7349 iter. is 1.2346464395523071\n",
            "Loss at 7399 iter. is 1.234325647354126\n",
            "Loss at 7449 iter. is 1.2340106964111328\n",
            "Loss at 7499 iter. is 1.2337021827697754\n",
            "Loss at 7549 iter. is 1.2333993911743164\n",
            "Loss at 7599 iter. is 1.2331023216247559\n",
            "Loss at 7649 iter. is 1.2328104972839355\n",
            "Loss at 7699 iter. is 1.2325241565704346\n",
            "Loss at 7749 iter. is 1.2322430610656738\n",
            "Loss at 7799 iter. is 1.2319672107696533\n",
            "Loss at 7849 iter. is 1.2316961288452148\n",
            "Loss at 7899 iter. is 1.2314296960830688\n",
            "Loss at 7949 iter. is 1.2311681509017944\n",
            "Loss at 7999 iter. is 1.2309112548828125\n",
            "Loss at 8049 iter. is 1.2306586503982544\n",
            "Loss at 8099 iter. is 1.2304104566574097\n",
            "Loss at 8149 iter. is 1.2301665544509888\n",
            "Loss at 8199 iter. is 1.2299264669418335\n",
            "Loss at 8249 iter. is 1.2296905517578125\n",
            "Loss at 8299 iter. is 1.2294585704803467\n",
            "Loss at 8349 iter. is 1.2292300462722778\n",
            "Loss at 8399 iter. is 1.2290056943893433\n",
            "Loss at 8449 iter. is 1.228784441947937\n",
            "Loss at 8499 iter. is 1.228567123413086\n",
            "Loss at 8549 iter. is 1.2283529043197632\n",
            "Loss at 8599 iter. is 1.2281420230865479\n",
            "Loss at 8649 iter. is 1.2279342412948608\n",
            "Loss at 8699 iter. is 1.2277300357818604\n",
            "Loss at 8749 iter. is 1.2275283336639404\n",
            "Loss at 8799 iter. is 1.227329969406128\n",
            "Loss at 8849 iter. is 1.227134108543396\n",
            "Loss at 8899 iter. is 1.2269413471221924\n",
            "Loss at 8949 iter. is 1.2267512083053589\n",
            "Loss at 8999 iter. is 1.2265636920928955\n",
            "Loss at 9049 iter. is 1.2263787984848022\n",
            "Loss at 9099 iter. is 1.226196527481079\n",
            "Loss at 9149 iter. is 1.226016640663147\n",
            "Loss at 9199 iter. is 1.2258391380310059\n",
            "Loss at 9249 iter. is 1.2256637811660767\n",
            "Loss at 9299 iter. is 1.2254912853240967\n",
            "Loss at 9349 iter. is 1.22532057762146\n",
            "Loss at 9399 iter. is 1.225151777267456\n",
            "Loss at 9449 iter. is 1.2249853610992432\n",
            "Loss at 9499 iter. is 1.2248207330703735\n",
            "Loss at 9549 iter. is 1.2246582508087158\n",
            "Loss at 9599 iter. is 1.2244980335235596\n",
            "Loss at 9649 iter. is 1.224339246749878\n",
            "Loss at 9699 iter. is 1.224182367324829\n",
            "Loss at 9749 iter. is 1.2240275144577026\n",
            "Loss at 9799 iter. is 1.2238739728927612\n",
            "Loss at 9849 iter. is 1.2237223386764526\n",
            "Loss at 9899 iter. is 1.2235727310180664\n",
            "Loss at 9949 iter. is 1.2234240770339966\n",
            "Loss at 9999 iter. is 1.2232773303985596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PftSe48cOIqX"
      },
      "source": [
        "### Напишите функцию для оцени качества модели\n",
        "\n",
        "Функция должна принимать на вход данные и значение целевой переменной возвращать значение ошибки (скаляр). Сравните ошибку на обучающей и валидационной выборке, сделайте выводы о том, переобучена ли модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tbwStLvHpH4"
      },
      "source": [
        "def evaluate(x, y, w, b):\n",
        "  y_hat = model(w, x, b)\n",
        "  return calc_loss(y,y_hat)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDfnt_N7Ho1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b415127d-5056-49ec-d5bf-de295f29bb6f"
      },
      "source": [
        "evaluate(x_val, y_val, w ,b)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=14.725935>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBey6N0_Hovq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zEUZ0nuHoqP"
      },
      "source": [
        "# 2. Слой Linear\n",
        "\n",
        "* Дополните линейный слой так, чтобы у него появились веса для сдвига. Для этого используйте метод `add_weight`. Размерность вектора с весами для сдвига равно размерности слоя на выходе (параметр `units`). \n",
        "* Для инициализации сдвига _нулями_ передайте `tf.keras.initializers.Zeros()` в качестве значения для параметра `add_weight(..., initializer=...)` \n",
        "* Измените метод `call` так, чтобы он использовал сдвиги.\n",
        "* Обучите модель на тех же данных, что и в первом задании."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RLCy8fpHokg"
      },
      "source": [
        "class Linear(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, initializer='glorot_uniform', **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.units = units\n",
        "    self.initializer = keras.initializers.get(initializer)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    print('build')\n",
        "    self.kernel = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=self.initializer,\n",
        "            name=\"kernel\",\n",
        "            trainable=True\n",
        "        )\n",
        "    self.bias = self.add_weight(\n",
        "            shape=(self.units),\n",
        "            initializer=self.initializer,\n",
        "            name='bias',\n",
        "            trainable=True\n",
        "         )\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel) + self.bias\n",
        "    \n",
        "  def get_config(self):\n",
        "    base_config = super(Linear, self).get_config()\n",
        "    config = {\"initializer\": keras.initializers.serialize(self.initializer)}\n",
        "    return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBIZAKkIU73k"
      },
      "source": [
        "## Запустите модель и сравните результаты с моделью из п.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KnrsYrYidHH",
        "outputId": "d9cd1794-b4f3-4daf-da09-36b045f279f7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/OTUS. DL Basic/HW_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYx8QgjCEw2r"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "\n",
        "logdir = os.path.join(\"/content/gdrive/My Drive/OTUS. DL Basic/HW_3\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "linear_layer = Linear(1)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                               min_delta=1e-4)\n",
        "model = keras.models.Sequential([linear_layer])\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), \n",
        "              loss='mse')"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkI7YjV2R34J"
      },
      "source": [
        "> **Обратите внимание**, что добавился параметр `validation_data`, а в `EarlyStopping` в ячейке выше значение параметра `monitor` заменено на `val_loss`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szjJdh4HRD3O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55d97699-0826-4728-8ca8-d1fd95706f69"
      },
      "source": [
        "history = model.fit(x_train, np.expand_dims(y_train, axis=-1), \n",
        "                    validation_data=(x_val, y_val),\n",
        "                    batch_size=512,\n",
        "                    epochs=100,\n",
        "                    callbacks=[early_stopping, tensorboard],\n",
        "                    verbose=1)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "build\n",
            "build\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-5cfde0b2f03a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:982 __call__\n        self._maybe_build(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    <ipython-input-97-3c292913279b>:19 build\n        trainable=True\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:614 add_weight\n        caching_device=caching_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:750 _add_variable_with_custom_getter\n        **kwargs_for_getter)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:145 make_variable\n        shape=variable_shape if variable_shape else None)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call\n        shape=shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2857 creator\n        return next_creator(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2857 creator\n        return next_creator(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2857 creator\n        return next_creator(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:685 variable_capturing_scope\n        lifted_initializer_graph=lifted_initializer_graph, **kwds)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:264 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:226 __init__\n        initial_value() if init_from_fn else initial_value,\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers/initializers_v2.py:397 __call__\n        return super(VarianceScaling, self).__call__(shape, dtype=_get_dtype(dtype))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops_v2.py:545 __call__\n        fan_in, fan_out = _compute_fans(scale_shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1410 _compute_fans\n        if len(shape) < 1:  # Just to avoid errors for constants.\n\n    TypeError: object of type 'int' has no len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVVy3pP0Rw_l"
      },
      "source": [
        "## Tensorboard\n",
        "> Выведите полученные результаты в tensorboard. Это сервис, который позволяет визуализировать процесс обучения модели, состояние графа и не только. \n",
        "\n",
        "Для запуска нужно \n",
        "* Установить расширение\n",
        "* Выполнить команду запуска, передав ей имя директории, в которую записывал логи `callbacks.Tensorboard`.\n",
        "\n",
        "Более подробно изучим tensorboard на будущих занятиях. Пока можете посмотреть вкладки scalars, graphs, distributions, histograms. В них содержится информация о метриках модели, графе, распередлениях и гистограммах параметров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1PTNxrrT_g3"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekdtast1UAA4"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r90JjdNMUDjg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}